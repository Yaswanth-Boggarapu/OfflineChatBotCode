{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_ip = [{'Question': 'What is today`s special?',\n",
    "          'Context': 'Today we got massala dosa with butter.'},\n",
    "          {'Question': 'What is your choice for a very hectic day',\n",
    "           'Context': 'I would prefer a cup of tea with some osmania biscuits.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepset/roberta-base-squad2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yash/Library/Python/3.12/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0 = tokenizer(QA_ip[0]['Question'], QA_ip[0]['Context'], return_tensors = \"pt\")\n",
    "outputs0 = model(**inputs0)\n",
    "\n",
    "inputs1 = tokenizer(QA_ip[1]['Question'], QA_ip[1]['Context'], return_tensors = \"pt\")\n",
    "outputs1 = model(**inputs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 1.6766e+00, -7.8161e+00, -8.4392e+00, -7.8511e+00, -7.9964e+00,\n",
       "         -7.8153e+00, -7.1464e+00, -9.1131e+00, -8.5812e+00, -7.8687e+00,\n",
       "          3.7835e-01,  7.4978e-01, -8.8387e-03,  3.3535e+00, -4.2681e+00,\n",
       "         -1.8460e+00, -4.1381e+00, -2.9300e+00, -1.0315e+00, -4.4062e+00,\n",
       "         -7.9840e+00]], grad_fn=<CloneBackward0>), end_logits=tensor([[ 2.1054, -7.5214, -7.8930, -8.4652, -4.1366, -7.6755, -7.0828, -6.5062,\n",
       "         -6.8500, -5.5986, -4.9334, -5.0838, -3.8720, -3.6491, -1.5593, -3.3260,\n",
       "          2.9141, -5.0796,  3.8652,  1.1853, -6.4293]],\n",
       "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is today`s special?  massala dosa with butter\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(\"----------------------\")\n",
    "\n",
    "answer_start_idx = torch.argmax(outputs0.start_logits)\n",
    "answer_end_idx = torch.argmax(outputs0.end_logits)\n",
    "\n",
    "\n",
    "answer_tokens = inputs0.input_ids[0, answer_start_idx : answer_end_idx + 1]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "\n",
    "print(QA_ip[0]['Question'], answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

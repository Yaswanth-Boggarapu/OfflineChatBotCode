{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1678 - loss: 2.1901\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2020 - loss: 2.1678 \n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2104 - loss: 2.1554 \n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2277 - loss: 2.1223 \n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1736 - loss: 2.1038 \n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2859 - loss: 2.0669 \n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2742 - loss: 2.0309 \n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3184 - loss: 2.0000 \n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3050 - loss: 1.9700 \n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2904 - loss: 1.8898 \n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3782 - loss: 1.8419 \n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3710 - loss: 1.7368 \n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3857 - loss: 1.6566 \n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5025 - loss: 1.5185 \n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5272 - loss: 1.3682 \n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6390 - loss: 1.3392 \n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5769 - loss: 1.2548 \n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5171 - loss: 1.2140 \n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5099 - loss: 1.1869 \n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 1.0231 \n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6312 - loss: 1.0310 \n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7353 - loss: 0.8484 \n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7236 - loss: 0.8633 \n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.7800 \n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.7693 \n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.6786 \n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.7025 \n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.6224 \n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.5678 \n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8019 - loss: 0.5937 \n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8221 - loss: 0.5251 \n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8998 - loss: 0.4218\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8556 - loss: 0.4745 \n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8663 - loss: 0.4596\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8540 - loss: 0.3463 \n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9496 - loss: 0.3355\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9177 - loss: 0.3008\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8976 - loss: 0.3642\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9177 - loss: 0.3596\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9379 - loss: 0.2589\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9037 - loss: 0.2834\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9441 - loss: 0.2562\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9161 - loss: 0.2927\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9379 - loss: 0.2805 \n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9060 - loss: 0.2910\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9457 - loss: 0.2142\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9434 - loss: 0.1750 \n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.1710\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1431\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.1194\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1666\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9798 - loss: 0.1451\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1000 \n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.1169\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.1036\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.1031 \n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0848\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0832\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9720 - loss: 0.0733 \n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0591 \n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0486\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9558 - loss: 0.1375\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0894 \n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0854\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0675\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0482\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0538\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0507 \n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0349\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0448\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0547 \n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0381 \n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0300\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0415\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0298\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.0583\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0282\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0233\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0340\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0317\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0345\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0201\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.0579\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0327\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0270\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0513\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0432 \n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0216\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0316\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0512\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0381\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0253\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.0912\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0212 \n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0222\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0152 \n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0181 \n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0302\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0268\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0206 \n",
      "Note: Enter 'quit' to exit the conversation.\n",
      "Bot: I think you're asking about GetSpicyDishesForFever. Here are some options: Adai Aviyal, Mysore Rava Dosai, Mysore Masala Dosai, Hot & Sour Veg Soup, Mysore Rava Masala Dosai, Chole Bhature, Rasam, Impossible Schezwan Fried Rice, Mushroom Chettinad. -- Intent: GetSpicyDishesForFever\n",
      "\n",
      "Bot: I think you're asking about RetrieveDishAllergicInfo. The allergic information for the dish is:  The item have an allergic content.. -- Intent: RetrieveDishAllergicInfo\n",
      "\n",
      "Bot: I think you're asking about RetrieveDishAllergicInfo. The allergic information for the dish is:  The item have an allergic content.. -- Intent: RetrieveDishAllergicInfo\n",
      "\n",
      "Goodbye! If you need help again, just ask.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text.strip()\n",
    "\n",
    "# Load intent configuration\n",
    "with open('/Users/yash/MagilHub/Project 1/OfflineChatBot/OfflineChatBotCode/intent1.json', 'r') as f:\n",
    "    intents_config = json.load(f)['intents']\n",
    "\n",
    "# Load menu data\n",
    "with open('/Users/yash/MagilHub/Project 1/OfflineChatBot/OfflineChatBotCode/mockMenu 1.json', 'r') as f:\n",
    "    menu_data = json.load(f)['menu']\n",
    "\n",
    "# Prepare the corpus for BM25 by combining 'itemName' and 'description' fields\n",
    "corpus = [\n",
    "    (item['itemName'] + \" \" + (item.get('description', '') if item.get('description') else \"\"))\n",
    "    for item in menu_data\n",
    "]\n",
    "bm25 = BM25Okapi([doc.split() for doc in corpus])\n",
    "\n",
    "# Data preprocessing for intent classification\n",
    "intents = []\n",
    "unique_intents = []\n",
    "text_input = []\n",
    "response_for_intent = {}\n",
    "query_for_intent = {}\n",
    "\n",
    "for intent in intents_config:\n",
    "    intent_name = intent['intent']\n",
    "\n",
    "    if intent_name not in unique_intents:\n",
    "        unique_intents.append(intent_name)\n",
    "\n",
    "    for text in intent['text']:\n",
    "        preprocessed_text = preprocess_text(text)\n",
    "        text_input.append(preprocessed_text)\n",
    "        intents.append(intent_name)\n",
    "\n",
    "    if intent_name not in response_for_intent:\n",
    "        response_for_intent[intent_name] = []\n",
    "    for response in intent['responses']:\n",
    "        response_for_intent[intent_name].append(response)\n",
    "\n",
    "    if intent_name not in query_for_intent:\n",
    "        query_for_intent[intent_name] = intent.get('query', '')\n",
    "\n",
    "tokenizer = Tokenizer(filters='', oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(text_input)\n",
    "sequences = tokenizer.texts_to_sequences(text_input)\n",
    "padded_sequences = pad_sequences(sequences, padding='pre')\n",
    "\n",
    "intent_to_index = {}\n",
    "categorical_target = []\n",
    "index = 0\n",
    "\n",
    "for intent in intents:\n",
    "    if intent not in intent_to_index:\n",
    "        intent_to_index[intent] = index\n",
    "        index += 1\n",
    "    categorical_target.append(intent_to_index[intent])\n",
    "\n",
    "num_classes = len(intent_to_index)\n",
    "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
    "\n",
    "categorical_vec = tf.keras.utils.to_categorical(categorical_target, num_classes=num_classes)\n",
    "categorical_vec = categorical_vec.astype('int32')\n",
    "\n",
    "# Model parameters\n",
    "epochs = 100\n",
    "embed_dim = 300\n",
    "lstm_num = 50\n",
    "output_dim = categorical_vec.shape[1]\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Embedding(len(tokenizer.word_index) + 1, embed_dim),\n",
    "    Bidirectional(LSTM(lstm_num, dropout=0.1)),\n",
    "    Dense(lstm_num, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    Dense(output_dim, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=1)\n",
    "\n",
    "# Predict intent with FuzzyWuzzy integration\n",
    "def predict_intent(sentence, threshold=90):\n",
    "    preprocessed_sentence = preprocess_text(sentence)\n",
    "    # First, try to predict intent using the trained model\n",
    "    sent_tokens = []\n",
    "    words = preprocessed_sentence.split()\n",
    "    for word in words:\n",
    "        if word in tokenizer.word_index:\n",
    "            sent_tokens.append(tokenizer.word_index[word])\n",
    "        else:\n",
    "            sent_tokens.append(tokenizer.word_index.get('<unk>', 0))\n",
    "    sent_tokens = tf.expand_dims(sent_tokens, 0)\n",
    "    pred = model(sent_tokens)\n",
    "    pred_class = np.argmax(pred.numpy(), axis=1)\n",
    "    intent_name = index_to_intent[pred_class[0]]\n",
    "    \n",
    "    # Now, use FuzzyWuzzy to verify or adjust the intent\n",
    "    # Gather all possible intent phrases\n",
    "    intent_phrases = {}\n",
    "    for intent in intents_config:\n",
    "        intent_phrases[intent['intent']] = [preprocess_text(text) for text in intent['text']]\n",
    "    \n",
    "    # Find the best matching intent based on FuzzyWuzzy\n",
    "    best_intent = None\n",
    "    highest_score = 0\n",
    "    for intent, phrases in intent_phrases.items():\n",
    "        for phrase in phrases:\n",
    "            score = fuzz.ratio(preprocessed_sentence, phrase)\n",
    "            if score > highest_score:\n",
    "                highest_score = score\n",
    "                best_intent = intent\n",
    "    \n",
    "    # If the highest fuzzy score is above the threshold, use it\n",
    "    if highest_score >= threshold:\n",
    "        intent_name = best_intent\n",
    "    \n",
    "    return intent_name\n",
    "\n",
    "# BM25 Document Retrieval with FuzzyWuzzy integration\n",
    "def retrieve_document(query, top_n=1):\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "    # Use BM25 to get initial scores\n",
    "    tokenized_query = preprocessed_query.split()\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Find top N documents based on BM25\n",
    "    top_indices = torch.topk(torch.tensor(doc_scores), k=top_n).indices.tolist()\n",
    "    retrieved_items = [menu_data[idx] for idx in top_indices]\n",
    "    \n",
    "    # If BM25 confidence is low, use FuzzyWuzzy to find better matches\n",
    "    if max(doc_scores) < 1:  # Threshold can be adjusted\n",
    "        # Create a list of all item names\n",
    "        item_names = [preprocess_text(item['itemName']) for item in menu_data]\n",
    "        \n",
    "        # Find the best match using FuzzyWuzzy\n",
    "        best_match = process.extractOne(preprocessed_query, item_names, scorer=fuzz.token_set_ratio)\n",
    "        if best_match and best_match[1] >= 80:\n",
    "            # Retrieve the item with the best match\n",
    "            matched_item = next((item for item in menu_data if preprocess_text(item['itemName']) == best_match[0]), None)\n",
    "            if matched_item:\n",
    "                retrieved_items = [matched_item]\n",
    "    \n",
    "    return retrieved_items[0] if retrieved_items else None\n",
    "\n",
    "# Function Definitions (unchanged)\n",
    "def get_spicy_dishes_for_fever():\n",
    "    return [item['itemName'] for item in menu_data if 'spicy' in (item.get('description', '') or '').lower()]\n",
    "\n",
    "def get_kids_friendly_dishes():\n",
    "    return [item['itemName'] for item in menu_data if item.get('kidsFriendly') == True]\n",
    "\n",
    "def get_vegan_dishes():\n",
    "    vegan_dishes = []\n",
    "    for item in menu_data:\n",
    "        if 'itemFilter' in item:\n",
    "            for filter_item in item['itemFilter']:\n",
    "                if filter_item['name'].lower() == 'vegan':\n",
    "                    vegan_dishes.append(item['itemName'])\n",
    "                    break\n",
    "    return vegan_dishes\n",
    "\n",
    "def get_nut_free_dishes():\n",
    "    return [item['itemName'] for item in menu_data if 'nuts' not in f\"{item.get('description', '')} {item.get('allergicInfo', '')}\".lower()]\n",
    "\n",
    "def get_fish_free_dishes():\n",
    "    return [item['itemName'] for item in menu_data if 'fish' not in f\"{item.get('description', '')} {item.get('allergicInfo', '')}\".lower()]\n",
    "\n",
    "def find_min_prep_time_dish_by_subcategory(subcategory):\n",
    "    filtered_items = [\n",
    "        item for item in menu_data \n",
    "        if item.get('subCategory') and item.get('subCategory', '').lower() == subcategory.lower()\n",
    "    ]\n",
    "    if filtered_items:\n",
    "        return min(filtered_items, key=lambda x: int(x['prepTimeInMins']))['itemName']\n",
    "    return None\n",
    "\n",
    "def retrieve_dish_description(query):\n",
    "    item = retrieve_document(query)\n",
    "    return item['description'] if item else 'Description not available.'\n",
    "\n",
    "def retrieve_dish_allergic_info(query):\n",
    "    item = retrieve_document(query)\n",
    "    return item['allergicInfo'] if item else 'Allergic info not available.'\n",
    "\n",
    "def retrieve_dish_price(query):\n",
    "    item = retrieve_document(query)\n",
    "    return item['price'] if item else 'Price not available.'\n",
    "\n",
    "# Modified handle_intent to return natural language responses\n",
    "def handle_intent(intent, query):\n",
    "    switcher = {\n",
    "        \"GetSpicyDishesForFever\": get_spicy_dishes_for_fever,\n",
    "        \"GetKidsFriendlyDishes\": get_kids_friendly_dishes,\n",
    "        \"GetVeganDishes\": get_vegan_dishes,\n",
    "        \"GetNutFreeDishes\": get_nut_free_dishes,\n",
    "        \"GetFishFreeDishes\": get_fish_free_dishes,\n",
    "        \"FindDishWithLeastPrepTime\": find_min_prep_time_dish_by_subcategory,\n",
    "        \"RetrieveDishDescription\": retrieve_dish_description,\n",
    "        \"RetrieveDishAllergicInfo\": retrieve_dish_allergic_info,\n",
    "        \"RetrieveDishPrice\": retrieve_dish_price,\n",
    "    }\n",
    "\n",
    "    func = switcher.get(intent)\n",
    "    if func:\n",
    "        # Handle cases where subcategory is needed\n",
    "        if intent == \"FindDishWithLeastPrepTime\":\n",
    "            subcategory = query.split('for')[-1].strip() if 'for' in query else None\n",
    "            if subcategory:\n",
    "                dish = func(subcategory)\n",
    "                if dish:\n",
    "                    return f\"The dish in the {subcategory} category that takes the least time to prepare is {dish}.\", intent\n",
    "                else:\n",
    "                    return f\"Sorry, I couldn't find any dish in the {subcategory} category.\", intent\n",
    "            else:\n",
    "                return \"Please specify a subcategory, so I can help you find the dish with the least preparation time.\", intent\n",
    "        # Pass the query for functions that need it (like RetrieveDishPrice)\n",
    "        elif intent in [\"RetrieveDishDescription\", \"RetrieveDishAllergicInfo\", \"RetrieveDishPrice\"]:\n",
    "            result = func(query)\n",
    "            if intent == \"RetrieveDishDescription\":\n",
    "                return f\"The description of the dish is: {result}.\", intent\n",
    "            elif intent == \"RetrieveDishAllergicInfo\":\n",
    "                return f\"The allergic information for the dish is: {result}.\", intent\n",
    "            elif intent == \"RetrieveDishPrice\":\n",
    "                return f\"The price of the dish is {result}.\", intent\n",
    "        # For other functions like GetNutFreeDishes and GetVeganDishes\n",
    "        else:\n",
    "            items = func()\n",
    "            if isinstance(items, list) and items:\n",
    "                item_list = ', '.join(items)\n",
    "                return f\"Here are some options: {item_list}.\", intent\n",
    "            else:\n",
    "                return \"Sorry, I couldn't find any relevant items.\", intent\n",
    "    else:\n",
    "        return \"I'm not sure how to help with that.\", intent\n",
    "\n",
    "# Modify the response generation to be more conversational\n",
    "def response(sentence):\n",
    "    intent_name = predict_intent(sentence)\n",
    "    intent_config = next((i for i in intents_config if i['intent'] == intent_name), None)\n",
    "\n",
    "    if intent_config and 'query' in intent_config:\n",
    "        result, intent = execute_query(intent_name, sentence)\n",
    "        return f\"I think you're asking about {intent_name}. {result}\", intent_name\n",
    "    else:\n",
    "        preprocessed_sentence = preprocess_text(sentence)\n",
    "        if 'description' in preprocessed_sentence:\n",
    "            result = retrieve_dish_description(preprocessed_sentence)\n",
    "            return f\"Let me tell you about this dish. {result}\", intent_name\n",
    "        elif 'price' in preprocessed_sentence:\n",
    "            result = retrieve_dish_price(preprocessed_sentence)\n",
    "            return f\"You might be wondering about the cost. The price is {result}.\", intent_name\n",
    "        else:\n",
    "            # Handle specific intent cases\n",
    "            result, intent = handle_intent(intent_name, sentence)\n",
    "            if result:\n",
    "                return f\"It seems like you're asking about {intent_name}. {result}\", intent_name\n",
    "            else:\n",
    "                # Use FuzzyWuzzy to suggest possible intents\n",
    "                possible_intents = [intent['intent'] for intent in intents_config]\n",
    "                best_match = process.extractOne(sentence, possible_intents, scorer=fuzz.partial_ratio)\n",
    "                if best_match and best_match[1] >= 60:\n",
    "                    suggested_intent = best_match[0]\n",
    "                    return f\"I'm not sure I understand. Did you mean {suggested_intent}?\", suggested_intent\n",
    "                else:\n",
    "                    return \"I'm not sure I understand. Could you clarify?\", intent_name\n",
    "\n",
    "# Execute query for specific intent\n",
    "def execute_query(intent_name, query):\n",
    "    if intent_name in query_for_intent:\n",
    "        query_code = query_for_intent[intent_name]\n",
    "        # Process the query_code directly if it's valid\n",
    "        return handle_intent(intent_name, query)\n",
    "    return \"It seems like I don't have an answer for that right now.\", intent_name\n",
    "\n",
    "# Test the system with user input\n",
    "print(\"Note: Enter 'quit' to exit the conversation.\")\n",
    "while True:\n",
    "    query = input('You: ')\n",
    "    if query.lower() == 'quit':\n",
    "        print(\"Goodbye! If you need help again, just ask.\")\n",
    "        break\n",
    "    bot_response, intent_type = response(query)\n",
    "    print(f'Bot: {bot_response} -- Intent: {intent_type}')\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

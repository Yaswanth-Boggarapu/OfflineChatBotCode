{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yash/Library/Python/3.12/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'ShowMenu', 'examples': ['Can I see the dinner menu?', 'Show me the breakfast options.', \"What's available for lunch?\", \"I'd like to see the dessert menu.\", 'What drinks are on the menu?', 'Do you have any appetizers?']}, {'intent': 'PlaceOrder', 'examples': ['I would like to order a pizza.', 'Can I get a salad?', \"I'd like to order two burgers.\", 'I want to place an order for room service.', 'Can I order a bottle of wine?', 'Please send a steak to my room.']}, {'intent': 'CancelOrder', 'examples': ['I need to cancel my order.', 'Please cancel the order for pasta.', 'Can you cancel my dessert order?', 'I want to cancel my drink order.', \"I'd like to stop my room service request.\"]}, {'intent': 'ModifyOrder', 'examples': ['Can I change my order?', 'I want to add a side of fries to my order.', \"I'd like to modify my order to include a drink.\", 'Can you remove the dessert from my order?', 'I need to update my order.']}, {'intent': 'SpecialRequests', 'examples': ['Can I get extra cheese on the pizza?', 'Can you make the pasta gluten-free?', 'Please make the burger without onions.', \"I'd like my steak cooked medium rare.\", 'Can I have extra sauce on the side?', 'Can I substitute fries for a salad?']}, {'intent': 'DietaryInquiry', 'examples': ['Do you have any vegan options?', 'Are there gluten-free dishes available?', 'Can I get a dairy-free dessert?', 'Do you offer vegetarian meals?', 'Is there a low-sodium menu?', 'Are any dishes peanut-free?']}, {'intent': 'MenuItemDetails', 'examples': ['What ingredients are in the Caesar salad?', 'How spicy is the curry?', 'What type of bread is used for the sandwich?', 'Is the soup made with chicken stock?', 'Can you tell me more about the fish dish?', 'What kind of cheese is on the burger?']}, {'intent': 'PortionSizeInquiry', 'examples': ['How big is the steak?', \"What's the portion size of the pasta?\", 'How many slices come with the pizza?', 'Is the salad large enough for two people?', 'How big is a serving of the fries?', 'What’s the size of the dessert?']}, {'intent': 'AvailableItemsInquiry', 'examples': ['Do you have any chicken dishes?', 'Is the lasagna available right now?', 'What desserts do you have today?', 'Is the salmon on the menu?', 'Can I order sushi?', 'Do you have lobster on the menu?']}, {'intent': 'BeverageMenuInquiry', 'examples': ['Can I see the wine list?', 'What cocktails do you have?', 'Do you have any non-alcoholic drinks?', 'What soft drinks are available?', 'Can I get a glass of red wine?', 'Do you serve coffee?']}, {'intent': 'CustomizeOrder', 'examples': ['Can I get the pasta with extra sauce?', 'Please make the pizza with thin crust.', 'Can I get my salad with dressing on the side?', 'Can I have my burger with a different cheese?', \"I'd like extra toppings on the sundae.\", 'Please remove the bacon from the sandwich.']}, {'intent': 'UnavailableItemsInquiry', 'examples': ['Is the chicken curry out of stock?', 'Do you have any dishes that are currently unavailable?', 'Is the chocolate cake available?', 'Are you out of salmon?', 'What items are not available today?', 'Can I order sushi, or is it sold out?']}, {'intent': 'AllergenInquiry', 'examples': ['Is the pizza peanut-free?', 'Does the salad contain nuts?', 'Are there any dairy products in the soup?', 'Is the bread gluten-free?', 'Does the dessert contain eggs?', 'Can you confirm if the dish is shellfish-free?']}, {'intent': 'WaitTimeInquiry', 'examples': ['How long will my food take?', 'What is the estimated wait time for my order?', 'When will my food be ready?', 'Can you tell me how long the kitchen will take?', 'How long for the room service order?', 'How much time until my drink is served?']}, {'intent': 'PricingInquiry', 'examples': ['How much is the steak?', 'What’s the price of the pizza?', 'Can you tell me the cost of the dessert?', 'What is the price for a glass of wine?', 'How much does the breakfast cost?', 'Is there an additional charge for extra toppings?']}, {'intent': 'FoodRecommendation', 'examples': ['What would you recommend for dinner?', 'Can you suggest a dish with seafood?', \"What's the chef's special today?\", 'Can you recommend something vegetarian?', 'What’s a popular dish on the menu?', \"What's a good dessert option?\"]}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load intents from intent.json\n",
    "with open('intent.json', 'r') as f:\n",
    "    data = json.load(f)  # Load the entire JSON file\n",
    "\n",
    "# Extract the intents list from the outer \"intents\" key\n",
    "\n",
    "intents = data.get(\"intents\", [])\n",
    "\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if intents were loaded correctly\n",
    "if not intents:\n",
    "    print(\"No intents found in the file!\")\n",
    "\n",
    "# Prepare texts and labels from the loaded JSON data\n",
    "texts = []\n",
    "labels = []\n",
    "for intent in intents:\n",
    "    if 'examples' in intent and 'intent' in intent:  # Ensure keys exist\n",
    "        for example in intent['examples']:\n",
    "            texts.append(example)\n",
    "            labels.append(intent['intent'])\n",
    "    else:\n",
    "        print(\"Invalid structure in intent:\", intent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yash/Library/Python/3.12/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Save label encoder for later use\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Tokenizer and model preparation\n",
    "MAX_LEN = 64\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(encoded_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define custom Dataset class\n",
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yash/Library/Python/3.12/lib/python/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = IntentDataset(texts, encoded_labels, tokenizer, max_len=MAX_LEN)\n",
    "data_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Set up training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train the model\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Accuracy: 1.0, Loss: 0.23828435192505518\n",
      "Epoch 2/20, Accuracy: 1.0, Loss: 0.21253727003932\n",
      "Epoch 3/20, Accuracy: 1.0, Loss: 0.19007027397553125\n",
      "Epoch 4/20, Accuracy: 1.0, Loss: 0.1828965743382772\n",
      "Epoch 5/20, Accuracy: 1.0, Loss: 0.160817580918471\n",
      "Epoch 6/20, Accuracy: 1.0, Loss: 0.15362074847022691\n",
      "Epoch 7/20, Accuracy: 1.0, Loss: 0.14295338715116182\n",
      "Epoch 8/20, Accuracy: 1.0, Loss: 0.1333911387870709\n",
      "Epoch 9/20, Accuracy: 1.0, Loss: 0.12532511291404566\n",
      "Epoch 10/20, Accuracy: 1.0, Loss: 0.11603035281101863\n",
      "Epoch 11/20, Accuracy: 1.0, Loss: 0.11305923325320084\n",
      "Epoch 12/20, Accuracy: 1.0, Loss: 0.10617491416633129\n",
      "Epoch 13/20, Accuracy: 1.0, Loss: 0.09753741199771564\n",
      "Epoch 14/20, Accuracy: 1.0, Loss: 0.09106385335326195\n",
      "Epoch 15/20, Accuracy: 1.0, Loss: 0.08846532180905342\n",
      "Epoch 16/20, Accuracy: 1.0, Loss: 0.0830174870789051\n",
      "Epoch 17/20, Accuracy: 1.0, Loss: 0.08127857434252898\n",
      "Epoch 18/20, Accuracy: 1.0, Loss: 0.07587949310739835\n",
      "Epoch 19/20, Accuracy: 1.0, Loss: 0.07038744414846103\n",
      "Epoch 20/20, Accuracy: 1.0, Loss: 0.06888404861092567\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    accuracy, loss = train_epoch(model, data_loader, optimizer, device)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Accuracy: {accuracy}, Loss: {loss}')\n",
    "\n",
    "# Save model using pickle\n",
    "with open('./Pickle Files/intent_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example of inference\n",
    "def predict_intent(text, model, tokenizer, label_encoder, max_len=64):\n",
    "    model.eval()\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    intent = label_encoder.inverse_transform(preds.cpu().numpy())\n",
    "\n",
    "    return intent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted intent: AllergenInquiry\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load label encoder and make predictions\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "example_text = \"Does it contain any nuts?\"\n",
    "predicted_intent = predict_intent(example_text, model, tokenizer, label_encoder)\n",
    "print(f'Predicted intent: {predicted_intent}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKBiRHdFP06t",
        "outputId": "5f0cca29-f891-44fe-e0d9-548602266d13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response for query 1: Context:\n",
            "Item Name: Rava Kichadi\n",
            "Description: A healthy breakfast option made with semolina and vegetables lightly tempered with spices cooked to perfection\n",
            "Special Instructions: MAKE IT LITTLE SPICY\n",
            "Allergic Info: NUTS and FISH.\n",
            "Price: 20\n",
            "---\n",
            "Item Name: South Indian Thali\n",
            "Description: Steamed rice, sambar, rasam, kootu, poriyal, kuzhambu, yogurt, appalam, chapati, kurma, pickle & Sweet\n",
            "Special Instructions: This is spl instruction\n",
            "Allergic Info: The item has allergic content.\n",
            "Price: 26\n",
            "Question: give price of rava kichadi?\n",
            "Answer: 20\n",
            "\n",
            "Context:\n",
            "Item Name: Rava Kichadi\n",
            "Description: A healthy breakfast option made with semolina and vegetables lightly tempered with spices cooked to perfection\n",
            "Special Instructions: MAKE IT LITTLE SPICY\n",
            "Allergic Info: NUTS and FISH.\n",
            "Price: 20\n",
            "---\n",
            "Item Name: South Indian Thali\n",
            "Description: Steamed rice, sambar, rasam, kootu, poriyal, kuzhambu,\n",
            "Response for query 2: Context:\n",
            "Item Name: Rava Kichadi\n",
            "Description: A healthy breakfast option made with semolina and vegetables lightly tempered with spices cooked to perfection\n",
            "Special Instructions: MAKE IT LITTLE SPICY\n",
            "Allergic Info: NUTS and FISH.\n",
            "Price: 20\n",
            "---\n",
            "Item Name: South Indian Thali\n",
            "Description: Steamed rice, sambar, rasam, kootu, poriyal, kuzhambu, yogurt, appalam, chapati, kurma, pickle & Sweet\n",
            "Special Instructions: This is spl instruction\n",
            "Allergic Info: The item has allergic content.\n",
            "Price: 26\n",
            "Question: does rava kichadi have nuts?\n",
            "Answer: No, it does not have nuts.\n",
            "\n",
            "Context:\n",
            "Item Name: Rava Kichadi\n",
            "Description: A healthy breakfast option made with semolina and vegetables lightly tempered with spices cooked to perfection\n",
            "Special Instructions: MAKE IT LITTLE SPICY\n",
            "Allergic Info: NUTS and FISH.\n",
            "Price: 20\n",
            "---\n",
            "Item Name: South Indian Thali\n",
            "Description: Steamed rice, sambar, rasam, kootu, poriy\n"
          ]
        }
      ],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from transformers import GPTJForCausalLM, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Download NLTK tokenization data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample menu data\n",
        "menu_data = [\n",
        "    {\n",
        "        \"itemId\": \"008341a8-e73c-4400-9143-4521f9e1befd\",\n",
        "        \"itemName\": \"Rava Kichadi\",\n",
        "        \"description\": \"A healthy breakfast option made with semolina and vegetables lightly tempered with spices cooked to perfection\",\n",
        "        \"subCategory\": \"South Indian Favorites\",\n",
        "        \"specialInstructions\": \"MAKE IT LITTLE SPICY\",\n",
        "        \"allergicInfo\": \"NUTS and FISH.\",\n",
        "        \"price\": \"20\"\n",
        "    },\n",
        "    {\n",
        "        \"itemId\": \"01cb3741-3755-4c98-a5ea-0262d1948d59\",\n",
        "        \"itemName\": \"South Indian Thali\",\n",
        "        \"description\": \"Steamed rice, sambar, rasam, kootu, poriyal, kuzhambu, yogurt, appalam, chapati, kurma, pickle & Sweet\",\n",
        "        \"subCategory\": \"Thali's\",\n",
        "        \"specialInstructions\": \"This is spl instruction\",\n",
        "        \"allergicInfo\": \"The item has allergic content.\",\n",
        "        \"price\": \"26\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Preprocess menu data\n",
        "def preprocess_menu(menu_data):\n",
        "    return [\n",
        "        f\"{item['itemName']} {item['description']} {item.get('specialInstructions', '')} {item.get('allergicInfo', '')} {item.get('price', '')}\"\n",
        "        for item in menu_data\n",
        "    ]\n",
        "\n",
        "# Tokenize the menu data\n",
        "tokenized_menu = [word_tokenize(doc.lower()) for doc in preprocess_menu(menu_data)]\n",
        "\n",
        "# Create BM25 object\n",
        "bm25 = BM25Okapi(tokenized_menu)\n",
        "\n",
        "def bm25_retrieve(query, top_n=3):\n",
        "    tokenized_query = word_tokenize(query.lower())\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    top_n_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
        "    retrieved_items = [menu_data[i] for i in top_n_indices]\n",
        "    return retrieved_items\n",
        "\n",
        "# Load GPT-J model and tokenizer\n",
        "model_name = \"EleutherAI/gpt-j-6B\"\n",
        "model = GPTJForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "def generate_response(context, query):\n",
        "    input_text = f\"Context:\\n{context}\\nQuestion: {query}\\nAnswer:\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Adjust max_length based on input size\n",
        "    input_length = inputs.input_ids.size(1)\n",
        "    max_length = input_length + 100  # Adding extra tokens for generation\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,  # Increase max_length\n",
        "            num_beams=4,\n",
        "            temperature=0.7,\n",
        "            early_stopping=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "\n",
        "def conversational_bot(query):\n",
        "    # Retrieve relevant menu items using BM25\n",
        "    retrieved_items = bm25_retrieve(query)\n",
        "\n",
        "    # Format the context to be clear and concise\n",
        "    context = \"\\n---\\n\".join([\n",
        "        f\"Item Name: {item['itemName']}\\nDescription: {item['description']}\\nSpecial Instructions: {item.get('specialInstructions', '')}\\nAllergic Info: {item.get('allergicInfo', '')}\\nPrice: {item.get('price', '')}\"\n",
        "        for item in retrieved_items\n",
        "    ])\n",
        "\n",
        "    # Generate response using GPT-J based on the context\n",
        "    response = generate_response(context, query)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example queries\n",
        "query1 = \"give price of rava kichadi?\"\n",
        "response1 = conversational_bot(query1)\n",
        "print(\"Response for query 1:\", response1)\n",
        "\n",
        "query2 = \"does rava kichadi have nuts?\"\n",
        "response2 = conversational_bot(query2)\n",
        "print(\"Response for query 2:\", response2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-m3feqAU-tM",
        "outputId": "ff3aad45-5c27-4d79-aa2d-e4564ed3a0e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant document IDs for query 'give me price of chicken?': [0, 1]\n",
            "Ranked document IDs and scores for query 'give me price of chicken?': [(1, 0.11494217953147351), (0, 0.11161230952358747)]\n",
            "\n",
            "Ranked Menu Items:\n",
            "Item Name: Mild Chicken Pasta, BM25 Score: 0.11494217953147351\n",
            "Item Name: Chicken Curry, BM25 Score: 0.11161230952358747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rank_bm25 import BM25Okapi\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample menu data (can be expanded with your larger dataset)\n",
        "menu_data = [\n",
        "    {\n",
        "        \"itemId\": \"1\",\n",
        "        \"itemName\": \"Chicken Curry\",\n",
        "        \"description\": \"Hot and spicy chicken dish\",\n",
        "        \"specialInstructions\": \"Extra spicy\",\n",
        "        \"allergicInfo\": \"Contains nuts\",\n",
        "        \"price\": \"15\"\n",
        "    },\n",
        "    {\n",
        "        \"itemId\": \"2\",\n",
        "        \"itemName\": \"Mild Chicken Pasta\",\n",
        "        \"description\": \"Creamy pasta with chicken\",\n",
        "        \"specialInstructions\": \"No garlic\",\n",
        "        \"allergicInfo\": \"Dairy\",\n",
        "        \"price\": \"12\"\n",
        "    },\n",
        "    {\n",
        "        \"itemId\": \"3\",\n",
        "        \"itemName\": \"Spicy Pasta\",\n",
        "        \"description\": \"Pasta with a spicy tomato sauce\",\n",
        "        \"specialInstructions\": \"\",\n",
        "        \"allergicInfo\": \"\",\n",
        "        \"price\": \"10\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 1: Tokenize the documents (menu items)\n",
        "def tokenize_document(document):\n",
        "    return word_tokenize(document.lower())\n",
        "\n",
        "# Step 2: Preprocess menu data into a list of combined item details\n",
        "def preprocess_menu(menu_data):\n",
        "    return [\n",
        "        f\"{item['itemName']} {item['description']} {item.get('specialInstructions', '')} {item.get('allergicInfo', '')} {item.get('price', '')}\"\n",
        "        for item in menu_data\n",
        "    ]\n",
        "\n",
        "# Step 3: Build an inverted index\n",
        "def build_inverted_index(menu_data):\n",
        "    inverted_index = defaultdict(list)\n",
        "    for doc_id, item in enumerate(menu_data):\n",
        "        # Tokenize each menu item\n",
        "        text = f\"{item['itemName']} {item['description']} {item.get('specialInstructions', '')} {item.get('allergicInfo', '')}\"\n",
        "        tokens = tokenize_document(text)\n",
        "        for token in set(tokens):  # Use set to avoid duplicate entries for the same word\n",
        "            inverted_index[token].append(doc_id)\n",
        "    return inverted_index\n",
        "\n",
        "# Step 4: Calculate document frequencies (DF) for each token in the inverted index\n",
        "def document_frequencies(inverted_index):\n",
        "    return {term: len(doc_ids) for term, doc_ids in inverted_index.items()}\n",
        "\n",
        "# Step 5: Retrieve relevant documents using inverted index\n",
        "def retrieve_documents(query, inverted_index):\n",
        "    query_tokens = tokenize_document(query)\n",
        "    relevant_docs = set()\n",
        "\n",
        "    # Collect documents that contain at least one query term\n",
        "    for token in query_tokens:\n",
        "        if token in inverted_index:\n",
        "            relevant_docs.update(inverted_index[token])\n",
        "\n",
        "    return list(relevant_docs)\n",
        "\n",
        "# Step 6: Rank the retrieved documents using BM25\n",
        "def rank_documents(query, menu_data, relevant_doc_ids):\n",
        "    # Preprocess the menu data\n",
        "    preprocessed_menu = preprocess_menu(menu_data)\n",
        "\n",
        "    # Tokenize the menu data for BM25\n",
        "    tokenized_menu = [tokenize_document(doc) for doc in preprocessed_menu]\n",
        "\n",
        "    # Create a BM25 object\n",
        "    bm25 = BM25Okapi(tokenized_menu)\n",
        "\n",
        "    # Tokenize the query\n",
        "    tokenized_query = tokenize_document(query)\n",
        "\n",
        "    # Get BM25 scores for relevant documents only\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "    # Filter scores for only the relevant documents\n",
        "    relevant_scores = [(doc_id, scores[doc_id]) for doc_id in relevant_doc_ids]\n",
        "\n",
        "    # Sort documents by their BM25 score in descending order\n",
        "    ranked_docs = sorted(relevant_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return the ranked documents and their scores\n",
        "    return ranked_docs\n",
        "\n",
        "# Build the inverted index\n",
        "inverted_index = build_inverted_index(menu_data)\n",
        "doc_freqs = document_frequencies(inverted_index)\n",
        "\n",
        "# Example query\n",
        "query = \"give me price of chicken?\"\n",
        "\n",
        "# Retrieve relevant documents based on the query\n",
        "relevant_docs = retrieve_documents(query, inverted_index)\n",
        "print(f\"Relevant document IDs for query '{query}':\", relevant_docs)\n",
        "\n",
        "# Rank the retrieved documents using BM25\n",
        "ranked_docs = rank_documents(query, menu_data, relevant_docs)\n",
        "print(f\"Ranked document IDs and scores for query '{query}':\", ranked_docs)\n",
        "\n",
        "# Display the ranked results (menu items)\n",
        "print(\"\\nRanked Menu Items:\")\n",
        "for doc_id, score in ranked_docs:\n",
        "    print(f\"Item Name: {menu_data[doc_id]['itemName']}, BM25 Score: {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDYBf6ZBaY0J",
        "outputId": "d565511c-b89b-407e-8d13-ac711d872983"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context:\n",
            "Item Name: Mild Chicken Pasta\n",
            "Description: Creamy pasta with chicken\n",
            "Price: 12\n",
            "Item Name: Chicken Curry\n",
            "Description: Hot and spicy chicken dish\n",
            "Price: 15\n",
            "User Query: give me price of chicken?\n",
            "Answer: 12\n",
            "\n",
            "Context:\n",
            "Item Name: Mild Chicken Pasta\n",
            "Description: Creamy pasta with chicken\n",
            "Price: 12\n",
            "Item Name: Chicken Curry\n",
            "Description: Hot and spicy chicken dish\n",
            "Price: 15\n",
            "User Query: give me price of chicken?\n",
            "Answer: 12\n",
            "\n",
            "Context:\n",
            "Item Name: Mild Chicken Pasta\n",
            "Description: Creamy pasta with chicken\n",
            "Price: 12\n",
            "Item Name: Chicken Curry\n",
            "Description: Hot and spicy chicken dish\n",
            "Price\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPTJForCausalLM, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load GPT-J model and tokenizer (make sure you have installed necessary packages and model)\n",
        "model_name = \"EleutherAI/gpt-j-6B\"\n",
        "model = GPTJForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "def generate_gpt_response(query, context):\n",
        "    input_text = f\"Context:\\n{context}\\nUser Query: {query}\\nAnswer:\"\n",
        "\n",
        "    # Tokenize the input\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=150, num_beams=5, temperature=0.7, early_stopping=True)\n",
        "\n",
        "    # Decode the generated response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Generate context based on ranked documents\n",
        "context = \"\\n\".join([f\"Item Name: {menu_data[doc_id]['itemName']}\\nDescription: {menu_data[doc_id]['description']}\\nPrice: {menu_data[doc_id]['price']}\" for doc_id, _ in ranked_docs])\n",
        "\n",
        "# Generate the GPT response\n",
        "gpt_response = generate_gpt_response(query, context)\n",
        "print(gpt_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZWyxNWGEAMl",
        "outputId": "72204b16-66de-4125-f999-0bdf9dee0555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are some items that might interest you:\n",
            "\n",
            "- Spicy Pasta: Pasta with a spicy tomato sauce (Price: $10)\n",
            "- Mild Chicken Pasta: Creamy pasta with chicken (Price: $12) | Special Instructions: No garlic | Allergic Info: Dairy\n",
            "Would you like more information about any of these?\n"
          ]
        }
      ],
      "source": [
        "def generate_template_response(query, ranked_docs, menu_data):\n",
        "    if not ranked_docs:\n",
        "        return \"Sorry, we don't have anything that matches your query.\"\n",
        "\n",
        "    # Construct a response using the top-ranked items\n",
        "    response = \"Here are some items that might interest you:\\n\"\n",
        "\n",
        "    for doc_id, score in ranked_docs:\n",
        "        item = menu_data[doc_id]\n",
        "        response += f\"\\n- {item['itemName']}: {item['description']} (Price: ${item['price']})\"\n",
        "        if item['specialInstructions']:\n",
        "            response += f\" | Special Instructions: {item['specialInstructions']}\"\n",
        "        if item['allergicInfo']:\n",
        "            response += f\" | Allergic Info: {item['allergicInfo']}\"\n",
        "\n",
        "    response += \"\\nWould you like more information about any of these?\"\n",
        "    return response\n",
        "\n",
        "# Generate a response based on the ranked documents\n",
        "response = generate_template_response(query, ranked_docs, menu_data)\n",
        "print(response)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
